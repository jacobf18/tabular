{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2000, 118])\n",
      "tensor([2000., 2000., 2000., 2000.]) tensor([1990., 1990., 1990., 1990.])\n"
     ]
    }
   ],
   "source": [
    "from abc import abstractmethod\n",
    "from tabicl.prior.dataset import SCMPrior\n",
    "from tabicl.prior.prior_config import DEFAULT_FIXED_HP, DEFAULT_SAMPLED_HP\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import loguniform\n",
    "import joblib\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.nested import nested_tensor\n",
    "from torch.utils.data import IterableDataset\n",
    "\n",
    "from typing import Optional, Tuple, Dict, Any, Union\n",
    "\n",
    "from mcpfn.prior.dataset import DummyPrior, MCARPrior\n",
    "    \n",
    "mcar_prior = MCARPrior(num_missing=10, max_features = 20, max_seq_len=100)\n",
    "\n",
    "# X, _, _ = mcar_prior.generate_dataset({\n",
    "#     'prior_type': 'mlp_scm',\n",
    "#     'num_features': 10,\n",
    "#     'num_classes': 2,\n",
    "#     'device': 'cpu',\n",
    "#     'seq_len': 20,\n",
    "#     'train_size': 10,\n",
    "#     'max_features': 20,\n",
    "#     'min_features': 5,\n",
    "#     'max_classes': 10,\n",
    "#     'cat_prob': 1.0,\n",
    "#     'scale_by_max_features': True,\n",
    "#     'multiclass_type': 'rank',\n",
    "#     'multiclass_ordered_prob': 0.2\n",
    "# })\n",
    "\n",
    "X, y, d, seq_lens, train_sizes = mcar_prior.get_batch(batch_size = 4)\n",
    "\n",
    "print(X.shape)\n",
    "print(seq_lens, train_sizes)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# sns.heatmap(torch.isnan(X), cbar=False, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:324] . file in archive is not in a subdirectory batch_000000.pt/: batch_000001.pt",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/batch_000000.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tabular/.venv/lib/python3.10/site-packages/torch/serialization.py:1433\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1431\u001b[0m overall_storage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1432\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_reader(opened_file) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m-> 1433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_is_torchscript_zip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1434\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1435\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m received a zip file that looks like a TorchScript archive\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1436\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m dispatching to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.jit.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.jit.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directly to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1437\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m silence this warning)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1438\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   1439\u001b[0m         )\n\u001b[1;32m   1440\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n",
      "File \u001b[0;32m~/tabular/.venv/lib/python3.10/site-packages/torch/serialization.py:1975\u001b[0m, in \u001b[0;36m_is_torchscript_zip\u001b[0;34m(zip_file)\u001b[0m\n\u001b[1;32m   1974\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_is_torchscript_zip\u001b[39m(zip_file):\n\u001b[0;32m-> 1975\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstants.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_all_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:324] . file in archive is not in a subdirectory batch_000000.pt/: batch_000001.pt"
     ]
    }
   ],
   "source": [
    "torch.load('data/batch_000000.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcpfn.model.bar_distribution import get_bucket_limits, FullSupportBarDistribution\n",
    "\n",
    "borders = torch.load('borders.pt')\n",
    "\n",
    "y = torch.randn(100)\n",
    "\n",
    "mean, std = torch.mean(y), torch.std(y)\n",
    "\n",
    "y_train_std = std.item() + 1e-20\n",
    "y_train_mean = mean.item()\n",
    "\n",
    "y_train = (y - y_train_mean) / y_train_std\n",
    "\n",
    "bardist = FullSupportBarDistribution(borders = borders)\n",
    "normalized_bardist = FullSupportBarDistribution(borders = borders * std + mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-93.0867, -26.1321, -22.6323,  ...,  23.6954,  27.1553,  86.9426])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bardist.borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x32c1a00d0>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(bardist.borders)\n",
    "plt.plot(normalized_bardist.borders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0074e-01, -4.3655e-01,  1.6527e+00,  9.0075e-01, -1.9251e+00,\n",
       "          1.6554e+00,  7.4727e-01,  3.0364e-01,  1.5618e+00, -1.3866e+00,\n",
       "          6.4264e-01,  1.9241e+00,  4.3499e-01, -2.4922e-01, -1.1652e+00,\n",
       "          2.6176e+00,  4.5972e-01,  1.6928e+00,  4.1489e-01, -8.8834e-02,\n",
       "          3.1503e+00,  2.9648e-01, -6.2812e-01,  7.7385e-01,  1.1338e+00,\n",
       "         -1.7390e-01, -1.8383e+00, -1.3864e+00, -9.8848e-02, -1.8397e+00,\n",
       "          3.1838e-01,  7.7940e-02, -3.7375e-03,  6.4821e-01, -6.8565e-01,\n",
       "         -6.4260e-01,  8.1026e-01, -8.2524e-01, -7.0349e-01, -1.9773e-01,\n",
       "         -3.0903e-01, -4.6896e-01, -1.4635e+00, -6.7517e-01,  5.8477e-01,\n",
       "          2.5487e-03,  1.2064e-01,  3.2227e-01,  3.0442e-01, -1.2604e+00,\n",
       "          6.9869e-01, -1.1476e+00,  3.5203e-01, -1.1030e+00,  8.3777e-01,\n",
       "         -6.5952e-01,  9.3750e-01, -8.5054e-01,  3.1865e-01, -2.4822e-01,\n",
       "          9.5897e-01, -3.3900e-01, -1.9574e-01, -7.3835e-01, -7.5363e-01,\n",
       "         -3.8466e-01, -1.9810e-01, -1.0569e+00,  1.0326e+00,  3.2431e-01,\n",
       "         -1.7249e-01,  2.8825e-01,  6.3557e-03, -1.4088e+00, -4.2582e-01,\n",
       "         -2.9546e-01, -2.0281e-01,  7.3162e-01,  2.0683e+00,  3.8655e-01,\n",
       "          8.4636e-01, -7.0238e-02, -1.7275e+00, -9.5226e-01, -1.0154e+00,\n",
       "         -7.5316e-01,  1.1055e+00, -4.8324e-01,  2.8650e-01, -6.6275e-01,\n",
       "          1.0770e+00,  1.9387e+00, -8.3097e-01, -4.1337e-01, -5.9802e-01,\n",
       "         -8.3504e-01,  5.8957e-01, -1.2685e+00, -1.4661e+00,  1.1715e+00]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3276, -1.8657, -0.8742,  ..., -0.3727,  0.7198,  0.0544]],\n",
       "\n",
       "        [[-0.8182,  0.7961,  1.1734,  ..., -1.0454, -2.2515,  2.0311]],\n",
       "\n",
       "        [[ 1.7532, -0.2757, -0.3792,  ...,  0.4926, -2.6405, -1.3726]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.2543,  1.9337, -0.3983,  ..., -0.4395,  1.2559, -0.6965]],\n",
       "\n",
       "        [[-1.0539, -0.8043,  1.5859,  ..., -0.8948, -1.1148,  0.2900]],\n",
       "\n",
       "        [[ 0.4916, -0.7614, -0.0715,  ...,  1.2553, -1.1526,  0.1139]]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.unsqueeze(0).permute(1,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-93.0867, -26.1321, -22.6323,  ...,  23.6954,  27.1553,  86.9426])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PerFeatureTransformer(\n",
       "  (encoder): SequentialEncoder(\n",
       "    (0): RemoveEmptyFeaturesEncoderStep()\n",
       "    (1): NanHandlingEncoderStep()\n",
       "    (2): VariableNumFeaturesEncoderStep()\n",
       "    (3): InputNormalizationEncoderStep()\n",
       "    (4): VariableNumFeaturesEncoderStep()\n",
       "    (5): LinearInputEncoderStep(\n",
       "      (layer): Linear(in_features=4, out_features=192, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (y_encoder): SequentialEncoder(\n",
       "    (0): NanHandlingEncoderStep()\n",
       "    (1): LinearInputEncoderStep(\n",
       "      (layer): Linear(in_features=2, out_features=192, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (transformer_encoder): LayerStack(\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x PerFeatureEncoderLayer(\n",
       "        (self_attn_between_features): MultiHeadAttention()\n",
       "        (self_attn_between_items): MultiHeadAttention()\n",
       "        (mlp): MLP(\n",
       "          (linear1): Linear(in_features=192, out_features=768, bias=False)\n",
       "          (linear2): Linear(in_features=768, out_features=192, bias=False)\n",
       "        )\n",
       "        (layer_norms): ModuleList(\n",
       "          (0-2): 3 x LayerNorm((192,), eps=1e-05, elementwise_affine=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder_dict): ModuleDict(\n",
       "    (standard): Sequential(\n",
       "      (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=768, out_features=5000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (feature_positional_embedding_embeddings): Linear(in_features=48, out_features=192, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tabpfn import TabPFNRegressor\n",
    "\n",
    "reg = TabPFNRegressor()\n",
    "\n",
    "X,y = torch.randn(100, 20), torch.randn(100)\n",
    "\n",
    "reg.fit(X,y)\n",
    "\n",
    "reg.model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = torch.randn(100, 1, 10), torch.randn(100)\n",
    "X_test = torch.randn(10, 1, 10)\n",
    "\n",
    "out = reg.model_.forward(torch.cat([torch.cat([X, torch.zeros_like(X_test)], dim=0), X_test], dim=0), y, single_eval_pos = X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4.0166, 2.5648, 2.0397,  ..., 2.1991, 2.4066, 3.9054]],\n",
       "\n",
       "        [[4.0166, 2.5648, 2.0397,  ..., 2.1991, 2.4066, 3.9054]],\n",
       "\n",
       "        [[4.0166, 2.5648, 2.0397,  ..., 2.1991, 2.4066, 3.9054]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[4.3162, 2.8634, 2.3291,  ..., 2.3070, 2.5205, 4.0783]],\n",
       "\n",
       "        [[4.5208, 3.0706, 2.5329,  ..., 2.6540, 2.8665, 4.3747]],\n",
       "\n",
       "        [[4.1786, 2.7237, 2.1918,  ..., 2.3088, 2.5186, 4.0333]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0365],\n",
       "        [1.0158],\n",
       "        [2.4398],\n",
       "        [1.0748],\n",
       "        [1.0473],\n",
       "        [1.0410],\n",
       "        [1.0570],\n",
       "        [1.6131],\n",
       "        [1.1282],\n",
       "        [1.2804]], grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.normalized_bardist_(out, torch.randn(10, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = reg.model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerFeatureTransformer(\n",
       "  (encoder): SequentialEncoder(\n",
       "    (0): RemoveEmptyFeaturesEncoderStep()\n",
       "    (1): NanHandlingEncoderStep()\n",
       "    (2): VariableNumFeaturesEncoderStep()\n",
       "    (3): InputNormalizationEncoderStep()\n",
       "    (4): VariableNumFeaturesEncoderStep()\n",
       "    (5): LinearInputEncoderStep(\n",
       "      (layer): Linear(in_features=4, out_features=192, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (y_encoder): SequentialEncoder(\n",
       "    (0): NanHandlingEncoderStep()\n",
       "    (1): LinearInputEncoderStep(\n",
       "      (layer): Linear(in_features=2, out_features=192, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (transformer_encoder): LayerStack(\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x PerFeatureEncoderLayer(\n",
       "        (self_attn_between_features): MultiHeadAttention()\n",
       "        (self_attn_between_items): MultiHeadAttention()\n",
       "        (mlp): MLP(\n",
       "          (linear1): Linear(in_features=192, out_features=768, bias=False)\n",
       "          (linear2): Linear(in_features=768, out_features=192, bias=False)\n",
       "        )\n",
       "        (layer_norms): ModuleList(\n",
       "          (0-2): 3 x LayerNorm((192,), eps=1e-05, elementwise_affine=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder_dict): ModuleDict(\n",
       "    (standard): Sequential(\n",
       "      (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=768, out_features=5000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (feature_positional_embedding_embeddings): Linear(in_features=48, out_features=192, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': False,\n",
       " '_parameters': {},\n",
       " '_buffers': {},\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_pre_hooks': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_hooks_with_kwargs': OrderedDict(),\n",
       " '_forward_hooks_always_called': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks_with_kwargs': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': {},\n",
       " 'in_keys': ['nan_indicators'],\n",
       " 'out_keys': ['nan_indicators'],\n",
       " 'normalize_by_used_features': False,\n",
       " 'num_features': 2,\n",
       " 'normalize_by_sqrt': True,\n",
       " 'number_of_used_features_': tensor([[1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1]])}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.model_.encoder[2].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': False,\n",
       " '_parameters': {},\n",
       " '_buffers': {},\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_pre_hooks': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_hooks_with_kwargs': OrderedDict(),\n",
       " '_forward_hooks_always_called': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks_with_kwargs': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': {},\n",
       " 'in_keys': ('main',),\n",
       " 'out_keys': ('main',),\n",
       " 'normalize_by_used_features': True,\n",
       " 'num_features': 2,\n",
       " 'normalize_by_sqrt': True,\n",
       " 'number_of_used_features_': tensor([[2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2]])}"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.model_.encoder[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': False,\n",
       " '_parameters': {},\n",
       " '_buffers': {},\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_pre_hooks': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_hooks_with_kwargs': OrderedDict(),\n",
       " '_forward_hooks_always_called': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks_with_kwargs': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': {},\n",
       " 'in_keys': ('main',),\n",
       " 'out_keys': ('main',),\n",
       " 'normalize_on_train_only': True,\n",
       " 'normalize_to_ranking': False,\n",
       " 'normalize_x': True,\n",
       " 'remove_outliers': False,\n",
       " 'remove_outliers_sigma': 4.0,\n",
       " 'seed': 0,\n",
       " 'lower_for_outlier_removal': None,\n",
       " 'upper_for_outlier_removal': None,\n",
       " 'mean_for_normalization': tensor([[-0.0344, -0.0156],\n",
       "         [-0.0527, -0.0624],\n",
       "         [ 0.0600,  0.0583],\n",
       "         [-0.0804,  0.1326],\n",
       "         [-0.1961,  0.1158]]),\n",
       " 'std_for_normalization': tensor([[1.0778, 0.9364],\n",
       "         [0.9556, 1.0733],\n",
       "         [0.9014, 0.9922],\n",
       "         [0.9037, 0.9678],\n",
       "         [0.9145, 1.0648]])}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.model_.encoder[3].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_new = SequentialEncoder(\n",
    "    reg.model_.encoder[4],\n",
    "    reg.model_.encoder[5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialEncoder(\n",
       "  (0): VariableNumFeaturesEncoderStep()\n",
       "  (1): LinearInputEncoderStep(\n",
       "    (layer): Linear(in_features=4, out_features=192, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': False,\n",
       " '_parameters': {},\n",
       " '_buffers': {},\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_pre_hooks': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_hooks_with_kwargs': OrderedDict(),\n",
       " '_forward_hooks_always_called': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks_with_kwargs': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': {},\n",
       " 'in_keys': ('main',),\n",
       " 'out_keys': ('main',),\n",
       " 'normalize_by_used_features': True,\n",
       " 'num_features': 2,\n",
       " 'normalize_by_sqrt': True,\n",
       " 'number_of_used_features_': tensor([[2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2]])}"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_new[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerFeatureTransformer(\n",
       "  (encoder): SequentialEncoder(\n",
       "    (0): RemoveEmptyFeaturesEncoderStep()\n",
       "    (1): NanHandlingEncoderStep()\n",
       "    (2): VariableNumFeaturesEncoderStep()\n",
       "    (3): InputNormalizationEncoderStep()\n",
       "    (4): VariableNumFeaturesEncoderStep()\n",
       "    (5): LinearInputEncoderStep(\n",
       "      (layer): Linear(in_features=4, out_features=192, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (y_encoder): SequentialEncoder(\n",
       "    (0): NanHandlingEncoderStep()\n",
       "    (1): LinearInputEncoderStep(\n",
       "      (layer): Linear(in_features=2, out_features=192, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (transformer_encoder): LayerStack(\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x PerFeatureEncoderLayer(\n",
       "        (self_attn_between_features): MultiHeadAttention()\n",
       "        (self_attn_between_items): MultiHeadAttention()\n",
       "        (mlp): MLP(\n",
       "          (linear1): Linear(in_features=192, out_features=768, bias=False)\n",
       "          (linear2): Linear(in_features=768, out_features=192, bias=False)\n",
       "        )\n",
       "        (layer_norms): ModuleList(\n",
       "          (0-2): 3 x LayerNorm((192,), eps=1e-05, elementwise_affine=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder_dict): ModuleDict(\n",
       "    (standard): Sequential(\n",
       "      (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=768, out_features=5000, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tabpfn.model.config import ModelConfig\n",
    "from tabpfn.model.transformer import PerFeatureTransformer\n",
    "\n",
    "from tabpfn.model.encoders import (\n",
    "    LinearInputEncoderStep,\n",
    "    NanHandlingEncoderStep,\n",
    "    SequentialEncoder,\n",
    "    InputNormalizationEncoderStep,\n",
    "    VariableNumFeaturesEncoderStep,\n",
    ")\n",
    "\n",
    "# encoder = SequentialEncoder(\n",
    "#     VariableNumFeaturesEncoderStep(num_features = 2),\n",
    "#     InputNormalizationEncoderStep(\n",
    "#         normalize_on_train_only = True,\n",
    "#         normalize_to_ranking = False,\n",
    "#         normalize_x = True,\n",
    "#         remove_outliers = False,\n",
    "#         remove_outliers_sigma = 4.0\n",
    "#     ),\n",
    "#     LinearInputEncoderStep(\n",
    "#         input_dim = 4,\n",
    "#         output_dim = 192,\n",
    "#         nan_handling = NanHandlingEncoderStep()\n",
    "#     )\n",
    "# )\n",
    "\n",
    "encoder = reg.model_.encoder\n",
    "\n",
    "encoder[3].mean_for_normalization = torch.zeros_like(encoder[3].mean_for_normalization)\n",
    "encoder[3].std_for_normalization = torch.ones_like(encoder[3].std_for_normalization)\n",
    "\n",
    "encoder[1]._buffers = {'feature_means_' : torch.zeros_like(encoder[1]._buffers['feature_means_'])}\n",
    "\n",
    "config = ModelConfig(\n",
    "    emsize=192,\n",
    "    features_per_group=2,\n",
    "    max_num_classes=10,\n",
    "    nhead=2,\n",
    "    remove_duplicate_features=True,\n",
    "    num_buckets=5000,\n",
    "    max_num_features=50\n",
    ")\n",
    "model = PerFeatureTransformer(config = config, encoder= encoder, n_out = 5000)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save encoder to file\n",
    "torch.save(encoder, \"encoder.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialEncoder(\n",
       "  (0): RemoveEmptyFeaturesEncoderStep()\n",
       "  (1): NanHandlingEncoderStep()\n",
       "  (2): VariableNumFeaturesEncoderStep()\n",
       "  (3): InputNormalizationEncoderStep()\n",
       "  (4): VariableNumFeaturesEncoderStep()\n",
       "  (5): LinearInputEncoderStep(\n",
       "    (layer): Linear(in_features=4, out_features=192, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_encoder = torch.load('encoder.pth', weights_only=False)\n",
    "loaded_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "new_X_train = torch.randn(1, 100, 20)\n",
    "new_y = torch.randn(1, 100)\n",
    "new_X_test = torch.randn(1, 10, 20)\n",
    "\n",
    "# model(torch.cat([new_X_train, new_X_test], dim=0), new_y, single_eval_pos = new_X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcpfn.model.mcpfn import MCPFN\n",
    "\n",
    "model = MCPFN(encoder_path = 'src/mcpfn/model/encoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 5000])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(torch.cat([new_X_train, new_X_test], dim=1), new_y)\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5689, -1.1021, -0.4471,  0.9601, -0.5685, -1.2178,  1.5860,  0.0055,\n",
      "         0.3445,  0.1032])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: -4.3115: 100%|██████████| 50/50 [00:11<00:00,  4.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# Let's try one training step\n",
    "\n",
    "y_test = torch.randn(10)\n",
    "print(y_test)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "step_progress = tqdm(range(50))\n",
    "\n",
    "# reset model parameters\n",
    "for layer in model.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "       layer.reset_parameters()\n",
    "\n",
    "for _ in step_progress:\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
    "\n",
    "    optim.zero_grad()\n",
    "\n",
    "    out = model(torch.cat([X, X_test], dim=0), y, single_eval_pos = X.shape[0])\n",
    "    loss = normalized_bardist(out, y_test).mean()\n",
    "    loss.backward()\n",
    "\n",
    "    optim.step()\n",
    "    \n",
    "    step_progress.set_description(f\"Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(torch.cat([X, X_test], dim=0), y, single_eval_pos = X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4668,  0.2356,  0.6985, -1.1044, -0.2697,  0.9062,  1.1155, -0.3559,\n",
      "        -0.6988,  1.0316])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.2513,  0.0882,  0.3636, -0.5889, -0.1727,  0.5199,  0.4821, -0.2265,\n",
       "        -0.3853,  0.3796], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_test)\n",
    "normalized_bardist.mean(out).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcpfn.model.bar_distribution import FullSupportBarDistribution\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "\n",
    "class OneHotAndLinear(nn.Linear):\n",
    "    \"\"\"Combines one-hot encoding and linear projection in a single efficient operation\n",
    "    to convert categorical indices to embeddings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_classes : int\n",
    "        Number of distinct categories for one-hot encoding\n",
    "\n",
    "    embed_dim : int\n",
    "        Output embedding dimension\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes: int, embed_dim: int):\n",
    "        super().__init__(num_classes, embed_dim)\n",
    "        self.num_classes = num_classes\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def forward(self, src: Tensor) -> Tensor:\n",
    "        \"\"\"Transform integer indices to dense embeddings.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        src : Tensor\n",
    "            Integer tensor of shape (batch_size, sequence_length) containing category indices\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tensor\n",
    "            Embedded representation of shape (batch_size, sequence_length, embed_dim)\n",
    "        \"\"\"\n",
    "        # Convert indices to one-hot vectors and apply linear projection\n",
    "        one_hot = F.one_hot(src.long(), self.num_classes).to(torch.float32)\n",
    "        return F.linear(one_hot, self.weight, self.bias)\n",
    "    \n",
    "class OneHotAndLinearBarDistribution(nn.Module):\n",
    "    def __init__(self, borders: Tensor, embed_dim: int):\n",
    "        super().__init__()\n",
    "        self.bar_distribution = FullSupportBarDistribution(borders = borders)\n",
    "        self.one_hot_and_linear = OneHotAndLinear(num_classes = len(borders) + 1, embed_dim = embed_dim)\n",
    "        \n",
    "    def forward(self, src: Tensor) -> Tensor:\n",
    "        \"\"\"Transform float values to dense embeddings using the BarDistribution.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        src : Tensor\n",
    "            Float tensor of shape (batch_size, sequence_length) containing values to embed\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tensor\n",
    "            Embedded representation of shape (batch_size, sequence_length, embed_dim)\n",
    "        \"\"\"\n",
    "        border_inds = self.bar_distribution.map_to_bucket_idx(src)\n",
    "        return self.one_hot_and_linear(border_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([      0.,   10000.,   20000.,   30000.,   40000.,   50000.,   60000.,\n",
       "          70000.,   80000.,   90000.,  100000.,  110000.,  120000.,  130000.,\n",
       "         140000.,  150000.,  160000.,  170000.,  180000.,  190000.,  200000.,\n",
       "         210000.,  220000.,  230000.,  240000.,  250000.,  260000.,  270000.,\n",
       "         280000.,  290000.,  300000.,  310000.,  320000.,  330000.,  340000.,\n",
       "         350000.,  360000.,  370000.,  380000.,  390000.,  400000.,  410000.,\n",
       "         420000.,  430000.,  440000.,  450000.,  460000.,  470000.,  480000.,\n",
       "         490000.,  500000.,  510000.,  520000.,  530000.,  540000.,  550000.,\n",
       "         560000.,  570000.,  580000.,  590000.,  600000.,  610000.,  620000.,\n",
       "         630000.,  640000.,  650000.,  660000.,  670000.,  680000.,  690000.,\n",
       "         700000.,  710000.,  720000.,  730000.,  740000.,  750000.,  760000.,\n",
       "         770000.,  780000.,  790000.,  800000.,  810000.,  820000.,  830000.,\n",
       "         840000.,  850000.,  860000.,  870000.,  880000.,  890000.,  900000.,\n",
       "         910000.,  920000.,  930000.,  940000.,  950000.,  960000.,  970000.,\n",
       "         980000.,  990000., 1000000.])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(100 + 1).float() * 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3768,  0.4734,  0.3515,  0.1267,  0.1809],\n",
       "         [ 0.0697, -0.0408,  0.0008, -0.0110,  0.3711],\n",
       "         [ 0.0934,  0.2529, -0.1078,  0.3877,  0.1241],\n",
       "         ...,\n",
       "         [ 0.2729, -0.0564,  0.2694,  0.2176,  0.2458],\n",
       "         [ 0.0697, -0.0408,  0.0008, -0.0110,  0.3711],\n",
       "         [ 0.0286,  0.1849,  0.2529,  0.0896,  0.2210]],\n",
       "\n",
       "        [[ 0.3768,  0.4734,  0.3515,  0.1267,  0.1809],\n",
       "         [ 0.1820,  0.2355,  0.3742,  0.4739,  0.3579],\n",
       "         [ 0.2617,  0.3889,  0.1455,  0.3633,  0.1481],\n",
       "         ...,\n",
       "         [ 0.2617,  0.3889,  0.1455,  0.3633,  0.1481],\n",
       "         [ 0.2617,  0.3889,  0.1455,  0.3633,  0.1481],\n",
       "         [ 0.3480,  0.0918,  0.2185,  0.4270,  0.5327]],\n",
       "\n",
       "        [[ 0.3480,  0.0918,  0.2185,  0.4270,  0.5327],\n",
       "         [ 0.2617,  0.3889,  0.1455,  0.3633,  0.1481],\n",
       "         [-0.0122,  0.1016,  0.1509,  0.2821,  0.3547],\n",
       "         ...,\n",
       "         [ 0.3480,  0.0918,  0.2185,  0.4270,  0.5327],\n",
       "         [ 0.2729, -0.0564,  0.2694,  0.2176,  0.2458],\n",
       "         [-0.0863,  0.1145,  0.0470,  0.4717,  0.1496]],\n",
       "\n",
       "        [[ 0.2729, -0.0564,  0.2694,  0.2176,  0.2458],\n",
       "         [ 0.0697, -0.0408,  0.0008, -0.0110,  0.3711],\n",
       "         [ 0.3768,  0.4734,  0.3515,  0.1267,  0.1809],\n",
       "         ...,\n",
       "         [ 0.0934,  0.2529, -0.1078,  0.3877,  0.1241],\n",
       "         [ 0.2729, -0.0564,  0.2694,  0.2176,  0.2458],\n",
       "         [ 0.3480,  0.0918,  0.2185,  0.4270,  0.5327]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = OneHotAndLinearBarDistribution(borders = get_bucket_limits(num_outputs = 10, ys = y[0]), embed_dim = 5)\n",
    "embed.forward(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Class values must be non-negative.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43membed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tabular/mcpfn/src/mcpfn/model/layers.py:112\u001b[0m, in \u001b[0;36mOneHotAndLinearBarDistribution.forward\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform float values to dense embeddings using the BarDistribution.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m    Embedded representation of shape (batch_size, sequence_length, embed_dim)\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m border_inds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbar_distribution\u001b[38;5;241m.\u001b[39mmap_to_bucket_idx(src)\n\u001b[0;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_hot_and_linear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mborder_inds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tabular/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tabular/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/tabular/mcpfn/src/mcpfn/model/layers.py:89\u001b[0m, in \u001b[0;36mOneHotAndLinear.forward\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform integer indices to dense embeddings.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m    Embedded representation of shape (batch_size, sequence_length, embed_dim)\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Convert indices to one-hot vectors and apply linear projection\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m one_hot \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_hot\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(src\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(one_hot, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Class values must be non-negative."
     ]
    }
   ],
   "source": [
    "embed.forward(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.randn(4, 2000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-93.0867, -26.1321, -22.6323,  ...,  23.6954,  27.1553,  86.9426])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('borders.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x32d842890>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.load('borders.pt')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(torch.load('borders.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.8737e+00, -2.4309e+00, -2.0873e+00, -1.9186e+00, -1.7537e+00,\n",
       "        -1.6525e+00, -1.5780e+00, -1.4858e+00, -1.3852e+00, -1.3385e+00,\n",
       "        -1.2987e+00, -1.2466e+00, -1.2169e+00, -1.1501e+00, -1.0999e+00,\n",
       "        -1.0378e+00, -1.0113e+00, -9.6897e-01, -9.2145e-01, -8.8394e-01,\n",
       "        -8.4370e-01, -8.0649e-01, -7.7390e-01, -7.4602e-01, -7.1809e-01,\n",
       "        -6.7251e-01, -6.4145e-01, -6.1843e-01, -5.9119e-01, -5.6030e-01,\n",
       "        -5.3457e-01, -5.0215e-01, -4.7838e-01, -4.5791e-01, -4.3009e-01,\n",
       "        -4.1545e-01, -3.8019e-01, -3.5528e-01, -3.3076e-01, -3.0420e-01,\n",
       "        -2.7439e-01, -2.4172e-01, -2.2195e-01, -1.9647e-01, -1.7418e-01,\n",
       "        -1.4726e-01, -1.2405e-01, -9.5777e-02, -7.5509e-02, -5.1924e-02,\n",
       "        -3.1530e-02, -3.8033e-03,  1.9635e-02,  4.3842e-02,  7.4794e-02,\n",
       "         9.6513e-02,  1.2021e-01,  1.6955e-01,  1.9146e-01,  2.2836e-01,\n",
       "         2.6040e-01,  2.8865e-01,  3.1268e-01,  3.3820e-01,  3.6411e-01,\n",
       "         3.8537e-01,  4.1810e-01,  4.4873e-01,  4.7566e-01,  5.1760e-01,\n",
       "         5.4440e-01,  5.7921e-01,  6.0155e-01,  6.4136e-01,  6.6868e-01,\n",
       "         7.0767e-01,  7.3015e-01,  7.6188e-01,  7.9488e-01,  8.4433e-01,\n",
       "         8.9623e-01,  9.2130e-01,  9.5632e-01,  9.9074e-01,  1.0510e+00,\n",
       "         1.0883e+00,  1.1430e+00,  1.1963e+00,  1.2480e+00,  1.3155e+00,\n",
       "         1.3687e+00,  1.4048e+00,  1.4566e+00,  1.5441e+00,  1.6261e+00,\n",
       "         1.7281e+00,  1.8248e+00,  1.9918e+00,  2.1905e+00,  2.4547e+00,\n",
       "         3.4628e+00])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bucket_limits(num_outputs = 100, ys = y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we just need to train on this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "batch1 = torch.load('/Users/jfeit/tabular/mcpfn/prior/batch_000000.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(760)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch1['X'].isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26227712])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch1['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 1024])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch1['y'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 13,  13,  13,  13,  36,  36,  36,  36,  37,  37,  37,  37,  47,  47,\n",
       "         47,  47,  42,  42,  42,  42,  97,  97,  97,  97,  37,  37,  37,  37,\n",
       "         75,  75,  75,  75,  43,  43,  43,  43,  70,  70,  70,  70,  73,  74,\n",
       "         74,  74,  55,  55,  55,  55,  46,  46,  46,  46,  94,  94,  94,  94,\n",
       "         18,  18,  18,  18,  60,  60,  60,  60,  44,  44,  44,  44,  83,  83,\n",
       "         83,  83,  47,  47,  47,  47,  36,  36,  36,  36,  20,  20,  20,  20,\n",
       "         30,  30,  30,  30,  43,  43,  43,  43,  61,  61,  61,  61,  33,  33,\n",
       "         33,  33,   5,   5,   5,   5, 100, 100, 100, 100,  39,  39,  39,  39,\n",
       "          4,   4,   4,   4,  79,  79,  79,  79,  97,  97,  97,  97,  80,  80,\n",
       "         80,  80,  62,  62,  62,  62,  10,  10,  10,  10,  52,  52,  52,  52,\n",
       "         82,  82,  82,  82,   8,   8,   8,   8,  58,  58,  58,  58,  78,  78,\n",
       "         78,  78,  12,  12,  12,  12,  72,  72,  72,  72,  80,  80,  80,  80,\n",
       "         97,  99,  99,  99,  29,  29,  29,  29,  55,  55,  55,  55,  17,  17,\n",
       "         17,  17,  43,  43,  43,  43,  59,  59,  59,  59,  82,  82,  82,  82,\n",
       "         45,  45,  45,  45,  91,  91,  91,  91,  13,  13,  13,  13,  14,  14,\n",
       "         14,  14,  68,  68,  68,  68,  22,  22,  22,  22,  57,  57,  57,  57,\n",
       "         12,  12,  12,  12,  73,  73,  73,  73,  33,  33,  33,  33,  13,  13,\n",
       "         13,  13,  19,  19,  19,  19,  49,  49,  49,  49,  19,  19,  19,  19,\n",
       "         43,  43,  43,  43,  14,  14,  14,  14,  35,  35,  35,  35,  79,  79,\n",
       "         79,  79,  16,  16,  16,  16,  84,  84,  84,  84,  94,  94,  94,  94,\n",
       "         15,  15,  15,  15,  62,  62,  62,  62,   9,   9,   9,   9,  89,  89,\n",
       "         89,  89,  15,  15,  15,  15,  48,  48,  48,  48,  62,  62,  62,  62,\n",
       "         37,  37,  37,  37,  12,  12,  12,  12,  79,  79,  79,  79,  20,  20,\n",
       "         20,  20,  80,  80,  80,  80,  28,  28,  28,  28,  81,  81,  81,  81,\n",
       "         84,  84,  84,  84,  90,  90,  90,  90,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,  25,  25,  25,  25,  74,  74,  74,  74,  40,  40,  40,  40,\n",
       "         28,  28,  28,  28,  11,  11,  11,  11,   8,   8,   8,   8,  73,  73,\n",
       "         73,  73,  61,  61,  61,  61,  28,  28,  28,  28,  88,  88,  88,  88,\n",
       "         57,  57,  57,  57,  67,  67,  67,  67,  18,  18,  18,  18,  16,  16,\n",
       "         16,  16,  59,  59,  59,  59,  77,  77,  77,  77,  85,  85,  85,  85,\n",
       "         81,  81,  81,  81,  89,  89,  89,  89,  79,  79,  79,  79,   4,   4,\n",
       "          4,   4,  11,  11,  11,  11,  84,  84,  84,  84,  75,  75,  75,  75,\n",
       "         27,  27,  27,  27,  84,  84,  84,  84,  65,  65,  65,  65,  54,  54,\n",
       "         54,  54,  87,  87,  87,  87,  40,  40,  40,  40,  29,  29,  29,  29,\n",
       "         26,  26,  26,  26,  98,  98,  98,  98,  57,  57,  57,  57,  53,  53,\n",
       "         53,  53,  41,  41,  41,  41,  32,  32,  32,  32,  97,  97,  97,  97,\n",
       "         25,  25,  25,  25,  88,  88,  88,  88])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch1['d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3267,  0.5456, -0.2666,  ...,  0.1564,  0.1221, -0.0616],\n",
       "         [-0.3267,  0.5456, -0.2666,  ...,  0.1564,  0.1221, -0.0616],\n",
       "         [-0.1359,  0.0529, -0.2173,  ..., -0.2137, -0.2599,  0.2424],\n",
       "         ...,\n",
       "         [-0.1359,  0.0529, -0.2173,  ..., -0.2137, -0.2599,  0.2424],\n",
       "         [-0.0175,  0.3406, -0.1104,  ..., -0.1093,  0.2604,  0.2327],\n",
       "         [-0.0101,  0.4443,  0.0548,  ...,  0.0775, -0.0382,  0.2546]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = torch.randint(0, 10, (1, 1900))\n",
    "\n",
    "one_hot = F.one_hot(y_train.long(), 10).to(torch.float32)\n",
    "\n",
    "lin = nn.Linear(10, 512)\n",
    "\n",
    "lin(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1900, 10])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1 = torch.load('prior/batch_000000.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch1['X'].shape[0] / (4 * 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X': tensor([ 1.4873,  0.9007, -2.1055,  ...,  0.5313,  2.5650,  0.4879]),\n",
       " 'y': tensor([[ 1.9269,  1.4873,  0.9007,  ...,  0.3189,  0.7836,  0.3841],\n",
       "         [-0.9928, -0.2558, -0.9586,  ...,  1.8776, -0.0146, -1.3936],\n",
       "         [-2.4740,  1.3030, -0.5953,  ..., -1.1701, -0.3380, -1.2186],\n",
       "         [-0.4628,  0.1498,  0.6902,  ...,  0.4652,  0.0260, -1.0705]]),\n",
       " 'd': tensor([20, 20, 20, 20]),\n",
       " 'seq_lens': tensor([2000., 2000., 2000., 2000.]),\n",
       " 'train_sizes': tensor([1990., 1990., 1990., 1990.]),\n",
       " 'batch_size': 4}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = batch1['X'].reshape((4, 2000, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X[0:1, :]\n",
    "\n",
    "# Compute mean along dim=2 (last dimension), ignoring NaNs\n",
    "mean_vals = torch.nanmean(X1, dim=2, keepdim=True)  # shape: [1, 2000, 1]\n",
    "\n",
    "# Find the NaNs\n",
    "nan_mask = torch.isnan(X1)  # shape: [1, 2000, 20]\n",
    "\n",
    "# Expand mean_vals to match x's shape for indexing\n",
    "mean_vals_expanded = mean_vals.expand_as(X1)\n",
    "\n",
    "# Replace NaNs with corresponding mean values\n",
    "X1[nan_mask] = mean_vals_expanded[nan_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0186,  0.6454,  2.6221,  0.0877, -2.3692, -1.5197, -0.4666,  0.3189,\n",
       "         0.7836,  0.3841])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch1['y'][0,1990:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1900, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3893,  1.0122, -0.0252,  ...,  0.0104,  0.6351,  0.7693],\n",
       "         [ 0.4426,  0.9237,  0.0062,  ...,  0.0411,  0.7069,  0.7064],\n",
       "         [ 0.3873,  1.0155, -0.0263,  ...,  0.0092,  0.6325,  0.7716],\n",
       "         ...,\n",
       "         [ 0.0725,  1.5377, -0.2118,  ..., -0.1722,  0.2090,  1.1428],\n",
       "         [ 0.2951,  1.1684, -0.0807,  ..., -0.0439,  0.5084,  0.8803],\n",
       "         [ 0.9194,  0.1325,  0.2872,  ...,  0.3160,  1.3485,  0.1440]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = torch.randn(1,1900)\n",
    "\n",
    "y_train = y_train.unsqueeze(2)\n",
    "\n",
    "lin = nn.Linear(1, 512)\n",
    "\n",
    "lin(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-93.0867, -26.1321, -22.6323,  ...,  23.6954,  27.1553,  86.9426])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jfeit/tabular/tabpfn/TabPFN/src/tabpfn/regressor.py:489: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-93.0867, -26.1321, -22.6323,  ...,  23.6954,  27.1553,  86.9426])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load diabetes dataset\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "# Split into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from tabpfn import TabPFNRegressor\n",
    "\n",
    "model = TabPFNRegressor(device=\"cpu\")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "model.bardist_.borders.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jfeit/tabular/.venv/lib/python3.10/site-packages/tabpfn/classifier.py:432: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TabPFNClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TabPFNClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>TabPFNClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "TabPFNClassifier()"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load breast cancer dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "# split into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = TabPFNClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5001])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bardist_.borders.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn import TabPFNRegressor, TabPFNClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x349c41540>]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.bardist_.borders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TabPFNRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 8,\n",
       " 'categorical_features_indices': None,\n",
       " 'softmax_temperature': 0.9,\n",
       " 'average_before_softmax': False,\n",
       " 'model_path': 'auto',\n",
       " 'device': 'auto',\n",
       " 'ignore_pretraining_limits': False,\n",
       " 'inference_precision': 'auto',\n",
       " 'fit_mode': 'fit_preprocessors',\n",
       " 'memory_saving_mode': 'auto',\n",
       " 'random_state': 0,\n",
       " 'n_jobs': -1,\n",
       " 'inference_config': None}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn import TabPFNRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-93.0867, -26.1321, -22.6323,  ...,  23.6954,  27.1553,  86.9426])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bardist_.borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.  5.  7. -1.]\n",
      " [ 1.  5. nan  2.]\n",
      " [ 1.  3.  6. nan]\n",
      " [nan  6.  1. -1.]\n",
      " [ 7. nan  5. nan]\n",
      " [ 2. nan  1.  7.]\n",
      " [-1. nan  3. nan]]\n",
      "[ 1.  3.  5.  7.  6. -1.  2.]\n",
      "[[ 7.  6.  3.  2.]\n",
      " [-1.  2.  5.  6.]]\n",
      "[nan nan]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_train_test_sets(X):\n",
    "    # Get missing indices in X\n",
    "    missing_indices = np.where(np.isnan(X))\n",
    "    \n",
    "    non_missing_indices = np.where(~np.isnan(X))\n",
    "    \n",
    "    train_X = np.zeros((len(non_missing_indices[0]), X.shape[0] + X.shape[1] - 2))\n",
    "    train_y = np.zeros(len(non_missing_indices[0]))\n",
    "    test_X = np.zeros((len(missing_indices[0]), X.shape[0] + X.shape[1] - 2))\n",
    "    test_y = np.zeros(len(missing_indices[0]))\n",
    "    \n",
    "    for k, (i,j) in enumerate(zip(non_missing_indices[0], non_missing_indices[1])):\n",
    "        # Get row without j-th column\n",
    "        row = np.delete(X[i,:], j)\n",
    "        # Get column without i-th row\n",
    "        col = np.delete(X[:,j], i)\n",
    "        \n",
    "        # Create train set\n",
    "        train_X[k,:] = np.concatenate((row, col))\n",
    "        train_y[k] = X[i,j]\n",
    "        \n",
    "    \n",
    "    for k, (i,j) in enumerate(zip(missing_indices[0], missing_indices[1])):\n",
    "        # Get row without j-th column\n",
    "        row = np.delete(X[i,:], j)\n",
    "        # Get column without i-th row\n",
    "        col = np.delete(X[:,j], i)\n",
    "        \n",
    "        # Create train set\n",
    "        test_X[k,:] = np.concatenate((row, col))\n",
    "        test_y[k] = np.nan\n",
    "        \n",
    "    return train_X, train_y, test_X, test_y\n",
    "    \n",
    "X = np.array([[1, 3, 5], [7, np.nan, 6], [-1, 2, np.nan]])\n",
    "train_X, train_y, test_X, test_y = create_train_test_sets(X)\n",
    "\n",
    "print(train_X)\n",
    "print(train_y)\n",
    "print(test_X)\n",
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tnsr = torch.from_numpy(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  3.,  5.],\n",
       "        [ 7., nan,  6.],\n",
       "        [-1.,  2., nan]], dtype=torch.float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
